{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b910fd3ff24a2e4",
   "metadata": {},
   "source": [
    "# Linear and Nonlinear Data Generating Process benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c7c3e95e974a2",
   "metadata": {},
   "source": [
    "## Linear Data Generating Process (DGP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15197ab988fb731e",
   "metadata": {},
   "source": [
    "Let $i=1,\\dots,n$. Draw confounders:\n",
    "\n",
    "$$\n",
    "\\text{tenure}_i \\sim \\mathcal N(24,\\ 12^2)\n",
    "$$\n",
    "$$\n",
    "\\text{sessions}_i \\sim \\mathcal N(5,\\ 2^2)\n",
    "$$\n",
    "$$\n",
    "\\text{spend}_i \\sim \\mathrm{Unif}(0,200)\n",
    "$$\n",
    "$$\n",
    "\\text{prem}_i \\sim \\mathrm{Bernoulli}(0.25)\n",
    "$$\n",
    "$$\n",
    "\\text{urban}_i \\sim \\mathrm{Bernoulli}(0.60)\n",
    "$$\n",
    "Stack them as\n",
    "\n",
    "$$\n",
    "X_i := \\big[\\ \\text{tenure}_i,\\ \\text{sessions}_i,\\ \\text{spend}_i,\\ \\text{prem}_i,\\ \\text{urban}_i\\ \\big]^\\top \\in \\mathbb{R}^5\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Treatment model\n",
    "\n",
    "$$\n",
    "m(x) \\equiv \\Pr(D=1\\mid X=x) = \\sigma\\big(\\alpha_d + x^\\top \\beta_t\\big),\n",
    "\\qquad\n",
    "\\sigma(z)=\\frac{1}{1+e^{-z}},\n",
    "$$\n",
    "\n",
    "with $\\alpha_d$ calibrated (by bisection) so that $\\mathbb{E}[D]\\approx 0.20$, and\n",
    "\n",
    "$$\n",
    "\\beta_t^\\top = \\big[, 0.08,\\ 0.12,\\ 0.004,\\ 0.25,\\ 0.10 \\big]\n",
    "$$\n",
    "\n",
    "Then\n",
    "$$D_i \\mid X_i \\sim \\mathrm{Bernoulli}\\big(m(X_i)\\big)$$\n",
    "\n",
    "---\n",
    "\n",
    "### Outcome model\n",
    "\n",
    "$$\n",
    "Y_i = \\alpha_y + X_i^\\top \\beta_y + \\Theta D_i + \\varepsilon_i,\n",
    "\\qquad\n",
    "\\varepsilon_i \\sim \\mathcal N(0,\\sigma_y^2),\n",
    "$$\n",
    "\n",
    "with $\\alpha_y=0,\\ \\sigma_y=1,\\ \\Theta=0.80$, and\n",
    "\n",
    "$$\n",
    "\\beta_y^\\top = \\big[0.05,\\ 0.60,\\ 0.005,\\ 0.80,\\ 0.20 \\big]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Oracle nuisances (IRM) and CATE\n",
    "\n",
    "$$\n",
    "m(x) = \\sigma\\!\\big(\\alpha_d + x^\\top \\beta_t\\big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "g_0(x) = \\mathbb{E}[Y \\mid X=x, D=0]\n",
    "       = \\alpha_y + x^\\top \\beta_y\n",
    "$$\n",
    "\n",
    "$$\n",
    "g_1(x) = \\mathbb{E}[Y \\mid X=x, D=1]\n",
    "       = \\alpha_y + x^\\top \\beta_y + \\Theta\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{CATE}(x) = g_1(x) - g_0(x)\n",
    "                 = \\Theta \\quad \\text{(constant)}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Targets\n",
    "\n",
    "$$\n",
    "\\Theta_{\\text{ATE}}\n",
    "= \\mathbb{E}\\big[Y(1)-Y(0)\\big]\n",
    "= \\Theta,\n",
    "\\qquad\n",
    "\\Theta_{\\text{ATTE}}\n",
    "= \\mathbb{E}\\big[Y(1)-Y(0)\\mid D=1\\big]\n",
    "= \\Theta.\n",
    "$$\n",
    "\n",
    "So under this constant-effect DGP:\n",
    "\n",
    "$$\n",
    "\\Theta_{\\text{ATE}} = \\Theta_{\\text{ATTE}} = 0.80.\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519e27e45fe8b5e8",
   "metadata": {},
   "source": [
    "### Let's generate the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441122f7a58f4578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T13:51:15.302934Z",
     "start_time": "2025-10-03T13:51:15.275555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment share ≈ 0.2052\n",
      "Ground-truth ATE from the DGP: 0.800\n",
      "Ground-truth ATT from the DGP: 0.800\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from causalkit.data import CausalDatasetGenerator\n",
    "\n",
    "confounder_specs: List[Dict[str, Any]] = [\n",
    "    {\"name\": \"tenure_months\",     \"dist\": \"normal\",   \"mu\": 24, \"sd\": 12},\n",
    "    {\"name\": \"avg_sessions_week\", \"dist\": \"normal\",   \"mu\": 5,  \"sd\": 2},\n",
    "    {\"name\": \"spend_last_month\",  \"dist\": \"uniform\",  \"a\": 0,   \"b\": 200},\n",
    "    {\"name\": \"premium_user\",      \"dist\": \"bernoulli\",\"p\": 0.25},\n",
    "    {\"name\": \"urban_resident\",    \"dist\": \"bernoulli\",\"p\": 0.60},\n",
    "]\n",
    "\n",
    "# Moderate, sensible effects by column name (linear, well-specified)\n",
    "# Outcome: higher sessions, tenure, spend, premium, urban -> higher Y\n",
    "beta_y_map = {\n",
    "    \"tenure_months\":     0.05,   # ~0.6 SD shift at +1 SD (12 months)\n",
    "    \"avg_sessions_week\": 0.60,   # strong engagement signal\n",
    "    \"spend_last_month\":  0.005,  # scale 0..200 => up to ~1 shift\n",
    "    \"premium_user\":      0.80,\n",
    "    \"urban_resident\":    0.20,\n",
    "}\n",
    "\n",
    "# Treatment score: moderate dependence on engagement, spend, premium, urban\n",
    "beta_d_map = {\n",
    "    \"tenure_months\":     0.08,\n",
    "    \"avg_sessions_week\": 0.12,\n",
    "    \"spend_last_month\":  0.004,\n",
    "    \"premium_user\":      0.25,\n",
    "    \"urban_resident\":    0.10,\n",
    "}\n",
    "\n",
    "def expand_beta_from_specs(specs: List[Dict[str, Any]], beta_map: Dict[str, float]) -> np.ndarray:\n",
    "    \"\"\"Create β aligned to the generator's X column order from confounder_specs.\"\"\"\n",
    "    betas = []\n",
    "    for spec in specs:\n",
    "        name = spec.get(\"name\", \"\")\n",
    "        dist = str(spec.get(\"dist\", \"normal\")).lower()\n",
    "        if dist in (\"normal\", \"uniform\", \"bernoulli\"):\n",
    "            betas.append(beta_map.get(name, 0.0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported dist in this simple setup: {dist}\")\n",
    "    return np.asarray(betas, dtype=float)\n",
    "\n",
    "beta_y = expand_beta_from_specs(confounder_specs, beta_y_map)\n",
    "beta_d = expand_beta_from_specs(confounder_specs, beta_d_map)\n",
    "\n",
    "gen = CausalDatasetGenerator(\n",
    "    theta=0.80,                 # constant treatment effect\n",
    "    tau=None,                   # use theta\n",
    "    beta_y=beta_y,              # linear connection between X and Y\n",
    "    beta_d=beta_d,              # linear connection between X and D\n",
    "    g_y=None, g_d=None,         # no nonlinearities\n",
    "    alpha_y=0.0,                # no intercept\n",
    "    alpha_d=0.0,                # no intercept\n",
    "    sigma_y=1.0,                # noise of y\n",
    "    outcome_type=\"continuous\",  # Gaussian Y\n",
    "    confounder_specs=confounder_specs,\n",
    "    u_strength_d=0.0,           # strength of latent confounder influence on treatment\n",
    "    u_strength_y=0.0,           # strength of latent confounder influence on outcome\n",
    "    propensity_sharpness=1.0,   # increase to make overlap harder\n",
    "    target_d_rate=0.20,         # rate of treatment assignment\n",
    "    seed=123                    # random seed for reproducibility\n",
    ")\n",
    "\n",
    "n = 10_000                      # Number of observations\n",
    "df = gen.generate(n)\n",
    "\n",
    "print(\"Treatment share ≈\", df[\"d\"].mean())\n",
    "true_ate = float(df[\"cate\"].mean())\n",
    "print(f\"Ground-truth ATE from the DGP: {true_ate:.3f}\")\n",
    "# Ground-truth ATT (on the natural scale): E[tau(X) | T=1] = mean CATE among the treated\n",
    "true_att = float(df.loc[df[\"d\"] == 1, \"cate\"].mean())\n",
    "print(f\"Ground-truth ATT from the DGP: {true_att:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25078b9f17a0ca2c",
   "metadata": {},
   "source": [
    "### Wrap it in CausalData Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efc74e981147010c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T13:51:15.524527Z",
     "start_time": "2025-10-03T13:51:15.511948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>d</th>\n",
       "      <th>tenure_months</th>\n",
       "      <th>avg_sessions_week</th>\n",
       "      <th>spend_last_month</th>\n",
       "      <th>premium_user</th>\n",
       "      <th>urban_resident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.903910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.130544</td>\n",
       "      <td>4.056687</td>\n",
       "      <td>181.570607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.388144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.586560</td>\n",
       "      <td>1.671561</td>\n",
       "      <td>182.793598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.456512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.455103</td>\n",
       "      <td>5.452889</td>\n",
       "      <td>125.185708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.535970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.327693</td>\n",
       "      <td>5.051629</td>\n",
       "      <td>4.932905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.965140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.042771</td>\n",
       "      <td>4.933996</td>\n",
       "      <td>23.577407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y    d  tenure_months  avg_sessions_week  spend_last_month  \\\n",
       "0  1.903910  0.0      12.130544           4.056687        181.570607   \n",
       "1  3.388144  0.0      19.586560           1.671561        182.793598   \n",
       "2  8.456512  1.0      39.455103           5.452889        125.185708   \n",
       "3  5.535970  1.0      26.327693           5.051629          4.932905   \n",
       "4  4.965140  1.0      35.042771           4.933996         23.577407   \n",
       "\n",
       "   premium_user  urban_resident  \n",
       "0           0.0             0.0  \n",
       "1           0.0             0.0  \n",
       "2           1.0             1.0  \n",
       "3           0.0             1.0  \n",
       "4           0.0             0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalkit.data import CausalData\n",
    "\n",
    "causal_data = CausalData(\n",
    "    df=df,\n",
    "    treatment=\"d\",\n",
    "    outcome=\"y\",\n",
    "    confounders=[\"tenure_months\",\n",
    "                 \"avg_sessions_week\",\n",
    "                 \"spend_last_month\",\n",
    "                 \"premium_user\",\n",
    "                 \"premium_user\",\n",
    "                 \"urban_resident\"]\n",
    ")\n",
    "\n",
    "causal_data.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f24be535324856",
   "metadata": {},
   "source": [
    "## Estimate ATE and ATTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a00d8ee46727429",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T13:51:23.995436Z",
     "start_time": "2025-10-03T13:51:15.753070Z"
    }
   },
   "outputs": [],
   "source": [
    "from causalkit.inference.ate import dml_ate\n",
    "\n",
    "# Estimate Average Treatment Effect (ATE)\n",
    "ate_result = dml_ate(causal_data, n_folds=4, normalize_ipw=False, store_diagnostic_data=False, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4922ddeee71fc7ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T13:51:24.012496Z",
     "start_time": "2025-10-03T13:51:24.010945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real ATE = 0.8 VS Estimated = 0.7506313322797796 in (0.6668061755942251, 0.8344564889653342)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Real ATE = 0.8 VS Estimated = {ate_result.get('coefficient')} in {ate_result.get('confidence_interval')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a6f5e4d57ea075",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T13:51:31.966588Z",
     "start_time": "2025-10-03T13:51:24.017404Z"
    }
   },
   "outputs": [],
   "source": [
    "from causalkit.inference.atte import dml_atte\n",
    "\n",
    "# Estimate Average Treatment Effect on Treatment (ATTE)\n",
    "atte_result = dml_atte(causal_data, n_folds=4, normalize_ipw=False, store_diagnostic_data=False, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7577a33e87f133cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T13:51:31.980456Z",
     "start_time": "2025-10-03T13:51:31.979097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real ATTE = 0.8 VS Estimated = 0.8238669785039335 in (0.7558326760362799, 0.8919012809715872)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Real ATTE = 0.8 VS Estimated = {atte_result.get('coefficient')} in {atte_result.get('confidence_interval')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273ae669024dc29f",
   "metadata": {},
   "source": [
    "The estimated ATE and ATTE are close to the ground truth values. But we got wide confidence_intervals.\n",
    "Adding more data makes the intervals narrower. You can try it when changes the n in GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6c03d1555a2cd4",
   "metadata": {},
   "source": [
    "## Nonlinear Data Generating Process (DGP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08a2121cdec0dee",
   "metadata": {},
   "source": [
    "Let $i=1,\\dots,n$. Draw confounders:\n",
    "\n",
    "$$\n",
    "\\text{tenure}_i \\sim \\mathcal N(24,\\ 12^2)\n",
    "$$\n",
    "$$\n",
    "\\text{sessions}_i \\sim \\mathcal N(5,\\ 2^2)\n",
    "$$\n",
    "$$\n",
    "\\text{spend}_i \\sim \\mathrm{Unif}(0,200)\n",
    "$$\n",
    "$$\n",
    "\\text{prem}_i \\sim \\mathrm{Bernoulli}(0.25)\n",
    "$$\n",
    "$$\n",
    "\\text{urban}_i \\sim \\mathrm{Bernoulli}(0.60)\n",
    "$$\n",
    "\n",
    "Stack them as\n",
    "\n",
    "$$\n",
    "X_i := \\big[\\ \\text{tenure}_i,\\ \\text{sessions}_i,\\ \\text{spend}_i,\\ \\text{prem}_i,\\ \\text{urban}_i\\ \\big]^\\top \\in \\mathbb{R}^5\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Treatment model\n",
    "\n",
    "Define\n",
    "$$\n",
    "m(x) \\equiv \\Pr(D=1\\mid X=x) = \\sigma\\big(\\alpha_d + g_d(x)\\big),\n",
    "\\qquad\n",
    "\\sigma(z)=\\frac{1}{1+e^{-z}},\n",
    "$$\n",
    "\n",
    "with $\\alpha_d$ calibrated (by bisection) so that $\\mathbb{E}[D]\\approx 0.20$.\n",
    "\n",
    "The nonlinear score includes **alignment with the treatment effect** $\\tau(x)$:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\begin{aligned}\n",
    "g_d(x) &= 1.10\\tanh\\big(0.06(\\text{spend}-100)\\big)\n",
    "+ 1.00,\\sigma\\big(0.60(\\text{sessions}-5)\\big) \\\n",
    "&\\quad + 0.50\\log!\\big(1+\\text{tenure}_+\\big)\n",
    "+ 0.50\\text{prem}\n",
    "+ 0.25\\text{urban} \\\n",
    "&\\quad + 0.90,\\text{prem}\\cdot\\mathbb{1}{\\text{spend}>120}\n",
    "+ 0.30,\\text{urban}\\cdot\\mathbb{1}{\\text{tenure}<12} \\\n",
    "&\\quad + 0.80,\\tau(x),\n",
    "\\end{aligned}\n",
    "}\n",
    "$$\n",
    "\n",
    "where $z_+ = \\max(z,0)$ and $\\mathbb{1}{\\cdot}$ is the indicator.\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "D_i \\mid X_i \\sim \\mathrm{Bernoulli}\\big(m(X_i)\\big)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Outcome model\n",
    "\n",
    "$$\n",
    "Y_i = \\alpha_y + g_y(X_i) + D_i,\\tau(X_i) + \\varepsilon_i,\n",
    "\\qquad\n",
    "\\varepsilon_i \\sim \\mathcal N(0,\\sigma_y^2),\n",
    "$$\n",
    "\n",
    "with $\\alpha_y=0,\\ \\sigma_y=1$.\n",
    "\n",
    "The baseline outcome component is nonlinear:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\begin{aligned}\n",
    "g_y(x) &= 0.70,\\tanh!\\big(0.03(\\text{spend}-80)\\big)\n",
    "+ 0.50,\\sqrt{\\text{sessions}*+}\n",
    "+ 0.40,\\log!\\big(1+\\text{tenure}*+\\big) \\\n",
    "&\\quad + 0.30,\\text{prem}\n",
    "+ 0.10,\\text{urban}\n",
    "- 0.10,\\mathbb{1}{\\text{spend}<20}.\n",
    "\\end{aligned}\n",
    "}\n",
    "$$\n",
    "\n",
    "The heterogeneous treatment effect (CATE) is\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\begin{aligned}\n",
    "\\tau(x) &= 0.40\n",
    "+ 0.60,\\sigma!\\big(0.40(\\text{sessions}-5)\\big)\n",
    "+ 2.00,\\text{prem}\\cdot\\mathbb{1}{\\text{spend}>120} \\\n",
    "&\\quad + 0.10,\\text{urban}\\cdot\\mathbb{1}{\\text{tenure}<12}.\n",
    "\\end{aligned}\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Oracle nuisances (IRM) and CATE\n",
    "\n",
    "$$\n",
    "m(x) = \\sigma!\\big(\\alpha_d + g_d(x)\\big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "g_0(x) = \\mathbb{E}[Y \\mid X=x, D=0]\n",
    "= \\alpha_y + g_y(x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "g_1(x) = \\mathbb{E}[Y \\mid X=x, D=1]\n",
    "= \\alpha_y + g_y(x) + \\tau(x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{CATE}(x) = g_1(x) - g_0(x)\n",
    "= \\tau(x)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Targets\n",
    "\n",
    "$$\n",
    "\\Theta_{\\text{ATE}}\n",
    "= \\mathbb{E}\\big[\\tau(X)\\big],\n",
    "\\qquad\n",
    "\\Theta_{\\text{ATTE}}\n",
    "= \\mathbb{E}\\big[\\tau(X)\\mid D=1\\big].\n",
    "$$\n",
    "\n",
    "Because $g_d(x)$ contains a **positive alignment term** ($+,0.80,\\tau(x)$)\n",
    "and shares the same high-$\\tau$ drivers (e.g. large sessions, premium with spend > 120),\n",
    "selection favors high-effect regions. Therefore,\n",
    "\n",
    "$$\n",
    "\\boxed{\\Theta_{\\text{ATTE}} > \\Theta_{\\text{ATE}}.}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to also make a short “constant-effect baseline” variant (no alignment term) so you can compare ATT = ATE vs. ATT > ATE side by side in the docs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e31b48aa1a6587",
   "metadata": {},
   "source": [
    "Absolutely — here’s that section rewritten with **clean line separation and spacing**, so it’s visually clear and consistent with your documentation style.\n",
    "This version renders perfectly in **Notion**, **Obsidian**, and **LaTeX** math blocks.\n",
    "\n",
    "---\n",
    "\n",
    "### Nonlinear score ( g_d(x) )\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\begin{aligned}\n",
    "g_d(x)\n",
    "&= 1.10,\\tanh!\\big(0.06(\\text{spend}-100)\\big) [4pt]\n",
    "&\\quad + 1.00,\\sigma!\\big(0.60(\\text{sessions}-5)\\big) [4pt]\n",
    "&\\quad + 0.50,\\log!\\big(1+\\text{tenure}_+\\big) [4pt]\n",
    "&\\quad + 0.50,\\text{prem} [4pt]\n",
    "&\\quad + 0.25,\\text{urban} [4pt]\n",
    "&\\quad + 0.90,\\text{prem}\\cdot\\mathbb{1}{\\text{spend}>120} [4pt]\n",
    "&\\quad + 0.30,\\text{urban}\\cdot\\mathbb{1}{\\text{tenure}<12} [4pt]\n",
    "&\\quad + 0.80,\\tau(x).\n",
    "\\end{aligned}\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to reformat the other boxed formulas (`g_y(x)` and `τ(x)`) in the same separated multi-line block style for visual consistency?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2bb40eefd8a61bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T07:57:46.434534Z",
     "start_time": "2025-10-04T07:57:46.391561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment share ≈ 0.2036\n",
      "Ground-truth ATE from the DGP: 0.913\n",
      "Ground-truth ATT from the DGP: 1.567\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from causalkit.data import CausalDatasetGenerator\n",
    "\n",
    "# 1) Confounders (independent)\n",
    "confounder_specs: List[Dict[str, Any]] = [\n",
    "    {\"name\": \"tenure_months\",     \"dist\": \"normal\",    \"mu\": 24, \"sd\": 12},\n",
    "    {\"name\": \"avg_sessions_week\", \"dist\": \"normal\",    \"mu\": 5,  \"sd\": 2},\n",
    "    {\"name\": \"spend_last_month\",  \"dist\": \"uniform\",   \"a\": 0,   \"b\": 200},\n",
    "    {\"name\": \"premium_user\",      \"dist\": \"bernoulli\", \"p\": 0.25},\n",
    "    {\"name\": \"urban_resident\",    \"dist\": \"bernoulli\", \"p\": 0.60},\n",
    "]\n",
    "\n",
    "# 2) Feature index map\n",
    "def feature_indices_from_specs(specs: List[Dict[str, Any]]) -> Dict[str, Tuple[int, ...]]:\n",
    "    idx, out = 0, {}\n",
    "    for spec in specs:\n",
    "        name = spec.get(\"name\", \"\")\n",
    "        dist = str(spec.get(\"dist\",\"normal\")).lower()\n",
    "        if dist in (\"normal\",\"uniform\",\"bernoulli\"):\n",
    "            out[name] = (idx,); idx += 1\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported dist: {dist}\")\n",
    "    return out\n",
    "\n",
    "feat = feature_indices_from_specs(confounder_specs)\n",
    "def col(X, key): return X[:, feat[key][0]]\n",
    "def _log1p_pos(x): return np.log1p(np.clip(x, 0.0, None))\n",
    "def _sqrt_pos(x):  return np.sqrt(np.clip(x, 0.0, None))\n",
    "def _ind(cond):    return cond.astype(float)\n",
    "def _sigmoid(z):   return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "# 3) g_d(x) -   nonlinear connection between X and D\n",
    "def g_d(X: np.ndarray) -> np.ndarray:\n",
    "    tenure = col(X, \"tenure_months\")\n",
    "    sess   = col(X, \"avg_sessions_week\")\n",
    "    spend  = col(X, \"spend_last_month\")\n",
    "    prem   = col(X, \"premium_user\")\n",
    "    urban  = col(X, \"urban_resident\")\n",
    "    tau_align = tau_func(X)                                       # explicit alignment\n",
    "    return (\n",
    "        1.10 * np.tanh(0.06*(spend - 100.0))\n",
    "      + 1.00 * _sigmoid(0.60*(sess - 5.0))                        # monotone sessions (matches tau)\n",
    "      + 0.50 * _log1p_pos(tenure)\n",
    "      + 0.50 * prem\n",
    "      + 0.25 * urban\n",
    "      + 0.90 * prem * _ind(spend > 120.0)                         # same driver as tau, larger coef\n",
    "      + 0.30 * urban * _ind(tenure < 12.0)                        # same interaction as tau\n",
    "      + 0.80 * tau_align                                         # direct alignment term (λ)\n",
    "    )\n",
    "\n",
    "\n",
    "# 4) g_y(x)  -   nonlinear connection between X and Y\n",
    "def g_y(X: np.ndarray) -> np.ndarray:\n",
    "    tenure = col(X, \"tenure_months\")\n",
    "    sess   = col(X, \"avg_sessions_week\")\n",
    "    spend  = col(X, \"spend_last_month\")\n",
    "    prem   = col(X, \"premium_user\")\n",
    "    urban  = col(X, \"urban_resident\")\n",
    "    return (\n",
    "        0.70 * np.tanh(0.03*(spend - 80.0))\n",
    "      + 0.50 * _sqrt_pos(sess)\n",
    "      + 0.40 * _log1p_pos(tenure)\n",
    "      + 0.30 * prem\n",
    "      + 0.10 * urban\n",
    "      - 0.10 * _ind(spend < 20.0)\n",
    "    )\n",
    "\n",
    "# 5) tau(x)  — nonlinear effect function (CATE)\n",
    "def tau_func(X: np.ndarray) -> np.ndarray:\n",
    "    tenure = col(X, \"tenure_months\")\n",
    "    sess   = col(X, \"avg_sessions_week\")\n",
    "    spend  = col(X, \"spend_last_month\")\n",
    "    prem   = col(X, \"premium_user\")\n",
    "    urban  = col(X, \"urban_resident\")\n",
    "    return (\n",
    "        0.40\n",
    "      + 0.60 * (1.0 / (1.0 + np.exp(-0.40*(sess - 5.0))))  # sigmoid\n",
    "      + 2 * prem * _ind(spend > 120.0)\n",
    "      + 0.10 * urban * _ind(tenure < 12.0)\n",
    "    )\n",
    "\n",
    "# 6) Generator — continuous outcome\n",
    "gen = CausalDatasetGenerator(\n",
    "    theta=0.0,                 # ignored; we pass tau\n",
    "    tau=tau_func,              # nonlinear effect\n",
    "    beta_y=None, beta_d=None,  # use nonlinear g_* only\n",
    "    g_y=g_y, g_d=g_d,          # nonlinear functions\n",
    "    alpha_y=0.0,               # baseline mean level, intercept\n",
    "    alpha_d=0.0,               # will be calibrated to target_d_rate\n",
    "    sigma_y=1.0,               # noise std for Y\n",
    "    outcome_type=\"continuous\", # outcome distribution\n",
    "    confounder_specs=confounder_specs,\n",
    "    target_d_rate=0.20,        # 20% will be treated\n",
    "    u_strength_d=0.0,          # strength of latent confounder influence on treatment\n",
    "    u_strength_y=0.0,          # strength of latent confounder influence on outcome\n",
    "    propensity_sharpness=1,    # increase to make overlap harder\n",
    "    seed=123                   # random seed for reproducibility\n",
    ")\n",
    "\n",
    "# 7) Generate\n",
    "n = 10_000                     # Number of observations\n",
    "df = gen.generate(n)\n",
    "\n",
    "\n",
    "print(\"Treatment share ≈\", df[\"d\"].mean())\n",
    "true_ate = float(df[\"cate\"].mean())\n",
    "print(f\"Ground-truth ATE from the DGP: {true_ate:.3f}\")\n",
    "# Ground-truth ATT (on the natural scale): E[tau(X) | T=1] = mean CATE among the treated\n",
    "true_att = float(df.loc[df[\"d\"] == 1, \"cate\"].mean())\n",
    "print(f\"Ground-truth ATT from the DGP: {true_att:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc325e362aa0337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T07:57:47.107133Z",
     "start_time": "2025-10-04T07:57:47.088227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>d</th>\n",
       "      <th>tenure_months</th>\n",
       "      <th>avg_sessions_week</th>\n",
       "      <th>spend_last_month</th>\n",
       "      <th>premium_user</th>\n",
       "      <th>urban_resident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.689404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.130544</td>\n",
       "      <td>4.056687</td>\n",
       "      <td>181.570607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.045282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.586560</td>\n",
       "      <td>1.671561</td>\n",
       "      <td>182.793598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.173595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.455103</td>\n",
       "      <td>5.452889</td>\n",
       "      <td>125.185708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.926216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.327693</td>\n",
       "      <td>5.051629</td>\n",
       "      <td>4.932905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.225088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.042771</td>\n",
       "      <td>4.933996</td>\n",
       "      <td>23.577407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y    d  tenure_months  avg_sessions_week  spend_last_month  \\\n",
       "0  0.689404  0.0      12.130544           4.056687        181.570607   \n",
       "1  3.045282  0.0      19.586560           1.671561        182.793598   \n",
       "2  7.173595  1.0      39.455103           5.452889        125.185708   \n",
       "3  1.926216  0.0      26.327693           5.051629          4.932905   \n",
       "4  1.225088  0.0      35.042771           4.933996         23.577407   \n",
       "\n",
       "   premium_user  urban_resident  \n",
       "0           0.0             0.0  \n",
       "1           0.0             0.0  \n",
       "2           1.0             1.0  \n",
       "3           0.0             1.0  \n",
       "4           0.0             0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalkit.data import CausalData\n",
    "\n",
    "causal_data = CausalData(\n",
    "    df=df,\n",
    "    treatment=\"d\",\n",
    "    outcome=\"y\",\n",
    "    confounders=[\"tenure_months\",\n",
    "                 \"avg_sessions_week\",\n",
    "                 \"spend_last_month\",\n",
    "                 \"premium_user\",\n",
    "                 \"premium_user\",\n",
    "                 \"urban_resident\"]\n",
    ")\n",
    "\n",
    "causal_data.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d9af69db63026d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T07:57:58.834492Z",
     "start_time": "2025-10-04T07:57:50.823984Z"
    }
   },
   "outputs": [],
   "source": [
    "from causalkit.inference.ate import dml_ate\n",
    "\n",
    "# Estimate Average Treatment Effect (ATE)\n",
    "ate_result = dml_ate(causal_data, n_folds=4, normalize_ipw=False, store_diagnostic_data=False, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d37eb3f48cb33009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T08:07:11.436616Z",
     "start_time": "2025-10-04T08:07:11.433545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real ATE = 0.913 VS Estimated = 0.9917276396749556 in (0.869543879249174, 1.1139114001007373)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Real ATE = {true_ate:.3f} VS Estimated = {ate_result.get('coefficient')} in {ate_result.get('confidence_interval')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f3b4cd518fb6f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T07:58:06.721129Z",
     "start_time": "2025-10-04T07:57:58.842832Z"
    }
   },
   "outputs": [],
   "source": [
    "from causalkit.inference.atte import dml_atte\n",
    "\n",
    "# Estimate Average Treatment Effect on Treatment (ATTE)\n",
    "atte_result = dml_atte(causal_data, n_folds=4, normalize_ipw=False, store_diagnostic_data=False, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d015d26b21a3168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T08:06:54.958210Z",
     "start_time": "2025-10-04T08:06:54.954814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real ATTE = 1.567 VS Estimated = 1.6433239376940343 in (1.4972790851652928, 1.7893687902227757)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Real ATTE = {true_att:.3f} VS Estimated = {atte_result.get('coefficient')} in {atte_result.get('confidence_interval')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc992dd6e8e96e3",
   "metadata": {},
   "source": [
    "The estimated ATE and ATTE are close to the ground truth values. But we got wide confidence_intervals.\n",
    "Adding more data makes the intervals narrower. You can try it when changes the n in GDP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}