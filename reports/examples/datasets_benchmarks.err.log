Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/jupyter_core/utils/__init__.py", line 154, in wrapped
    asyncio.get_running_loop()
RuntimeError: no running event loop

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/nbclient/client.py", line 1319, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/jupyter_core/utils/__init__.py", line 158, in wrapped
    return loop.run_until_complete(inner)
  File "/opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------

import numpy as np
import pandas as pd

# If available in your environment:
from causalkit.data import CausalDatasetGenerator

# Reproducibility
SEED = 42
np.random.seed(SEED)

# Number of observations
n = 10000

# Confounders schema
# These are illustrative product/behavior/user attributes
confounder_specs = [
    {"name": "tenure_months", "dist": "normal", "mu": 18, "sd": 12},  # app tenure
    {"name": "sessions_per_week", "dist": "normal", "mu": 6, "sd": 3},  # engagement
    {"name": "spend_last_30d", "dist": "uniform", "a": 0, "b": 300},  # recent spend
    {"name": "premium_user", "dist": "bernoulli", "p": 0.2},  # subscription
    {"name": "urban_resident", "dist": "bernoulli", "p": 0.65},  # geography
]

# True causal effect on ARPPU (on the natural/mean scale)
theta_arppu = 4.0

# Outcome noise (ARPPU is positive and often heavy-tailed; this is a simple Gaussian noise)
sigma_y = 8.0

# Target share of users exposed to the feature
target_t_rate = 0.4

# How confounders affect ARPPU (baseline; additive)
# Order must match confounder_specs
beta_y = np.array([
    0.08,  # + per tenure month
    0.60,  # + per weekly session
    0.03,  # + per recent spend unit (scaled here)
    6.00,  # premium users have higher ARPPU
    2.00,  # urban residents slightly higher ARPPU
], dtype=float)

# How confounders affect feature exposure (log-odds scale)
beta_t = np.array([
    0.02,  # tenure increases likelihood of exposure
    0.15,  # more sessions -> more likely to get feature
    0.004,  # recent spend -> more likely to get feature
    1.00,  # premium users prioritized
    0.35,  # urban residents slightly more likely
], dtype=float)

gen = CausalDatasetGenerator(
    theta=theta_arppu,
    outcome_type="continuous",
    sigma_y=sigma_y,
    target_t_rate=target_t_rate,
    seed=SEED,
    confounder_specs=confounder_specs,
    beta_y=beta_y,
    beta_t=beta_t,
)

# Create dataset
causal_data = gen.to_causal_data(
    n=n,
    confounders = [
    "tenure_months",
    "sessions_per_week",
    "spend_last_30d",
    "premium_user",
    "urban_resident",
]
)

# Show first few rows
causal_data.df.head()

------------------


[0;31m---------------------------------------------------------------------------[0m
[0;31mTypeError[0m                                 Traceback (most recent call last)
Cell [0;32mIn[1], line 52[0m
[1;32m     43[0m [38;5;66;03m# How confounders affect feature exposure (log-odds scale)[39;00m
[1;32m     44[0m beta_t [38;5;241m=[39m np[38;5;241m.[39marray([
[1;32m     45[0m     [38;5;241m0.02[39m,  [38;5;66;03m# tenure increases likelihood of exposure[39;00m
[1;32m     46[0m     [38;5;241m0.15[39m,  [38;5;66;03m# more sessions -> more likely to get feature[39;00m
[0;32m   (...)[0m
[1;32m     49[0m     [38;5;241m0.35[39m,  [38;5;66;03m# urban residents slightly more likely[39;00m
[1;32m     50[0m ], dtype[38;5;241m=[39m[38;5;28mfloat[39m)
[0;32m---> 52[0m gen [38;5;241m=[39m [43mCausalDatasetGenerator[49m[43m([49m
[1;32m     53[0m [43m    [49m[43mtheta[49m[38;5;241;43m=[39;49m[43mtheta_arppu[49m[43m,[49m
[1;32m     54[0m [43m    [49m[43moutcome_type[49m[38;5;241;43m=[39;49m[38;5;124;43m"[39;49m[38;5;124;43mcontinuous[39;49m[38;5;124;43m"[39;49m[43m,[49m
[1;32m     55[0m [43m    [49m[43msigma_y[49m[38;5;241;43m=[39;49m[43msigma_y[49m[43m,[49m
[1;32m     56[0m [43m    [49m[43mtarget_t_rate[49m[38;5;241;43m=[39;49m[43mtarget_t_rate[49m[43m,[49m
[1;32m     57[0m [43m    [49m[43mseed[49m[38;5;241;43m=[39;49m[43mSEED[49m[43m,[49m
[1;32m     58[0m [43m    [49m[43mconfounder_specs[49m[38;5;241;43m=[39;49m[43mconfounder_specs[49m[43m,[49m
[1;32m     59[0m [43m    [49m[43mbeta_y[49m[38;5;241;43m=[39;49m[43mbeta_y[49m[43m,[49m
[1;32m     60[0m [43m    [49m[43mbeta_t[49m[38;5;241;43m=[39;49m[43mbeta_t[49m[43m,[49m
[1;32m     61[0m [43m)[49m
[1;32m     63[0m [38;5;66;03m# Create dataset[39;00m
[1;32m     64[0m causal_data [38;5;241m=[39m gen[38;5;241m.[39mto_causal_data(
[1;32m     65[0m     n[38;5;241m=[39mn,
[1;32m     66[0m     confounders [38;5;241m=[39m [
[0;32m   (...)[0m
[1;32m     72[0m ]
[1;32m     73[0m )

[0;31mTypeError[0m: CausalDatasetGenerator.__init__() got an unexpected keyword argument 'target_t_rate'

