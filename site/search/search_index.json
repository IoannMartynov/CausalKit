{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CausalKit","text":"<p>CausalKit is a Python package for causal inference that provides tools for designing, implementing, and analyzing causal inference experiments.</p>"},{"location":"#overview","title":"Overview","text":"<p>CausalKit simplifies the process of conducting causal inference studies by providing:</p> <ul> <li>Data Generation: Tools for generating synthetic data for A/B tests and randomized controlled trials</li> <li>Experimental Design: Utilities for splitting traffic and designing experiments</li> <li>Statistical Analysis: Methods for analyzing experimental results using various statistical approaches</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install causalkit\n</code></pre> <p>Or clone the repository and install from source:</p> <pre><code>git clone https://github.com/yourusername/causalkit.git\ncd causalkit\npip install -e .\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Here's a simple example of generating A/B test data and analyzing the results:</p> <pre><code>import causalkit\nfrom causalkit.data import generate_ab_test_data\nfrom causalkit.inference import compare_ab\n\n# Generate synthetic A/B test data\ndf = generate_ab_test_data(\n    n_samples={\"A\": 5000, \"B\": 5000},\n    conversion_rates={\"A\": 0.10, \"B\": 0.12}\n)\n\n# Extract control and treatment data\ncontrol = df[df['group'] == 'A']['conversion'].values\ntreatment = df[df['group'] == 'B']['conversion'].values\n\n# Compare the results\ncompare_ab(control, treatment)\n</code></pre>"},{"location":"#features","title":"Features","text":""},{"location":"#data-generation","title":"Data Generation","text":"<ul> <li>Generate A/B test data with customizable parameters</li> <li>Create randomized controlled trial (RCT) data</li> <li>Generate observational data for more complex causal inference scenarios</li> </ul>"},{"location":"#experimental-design","title":"Experimental Design","text":"<ul> <li>Split traffic for experiments with customizable ratios</li> <li>Support for stratified splitting to maintain distribution of key variables</li> </ul>"},{"location":"#analysis","title":"Analysis","text":"<ul> <li>Two-sample t-tests for comparing control and treatment groups</li> <li>OLS regression with treatment dummies</li> <li>Advanced methods like Partial Linear Regression (PLR) using DoubleML</li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of the LICENSE file.</p>"},{"location":"api/analysis/","title":"Analysis Module","text":"<p>The <code>causalkit.analysis</code> module provides statistical analysis tools for causal inference.</p>"},{"location":"api/analysis/#overview","title":"Overview","text":"<p>This module includes functions for:</p> <ul> <li>Performing t-tests on causaldata objects to compare target variables between treatment groups</li> <li>Calculating p-values, absolute differences, and relative differences with confidence intervals</li> </ul>"},{"location":"api/analysis/#t-test-analysis","title":"T-Test Analysis","text":"<p>The <code>ttest</code> function performs a t-test on a causaldata object to compare the target variable between treatment groups. This is particularly useful for analyzing the results of A/B tests or randomized controlled trials (RCTs).</p>"},{"location":"api/analysis/#key-features","title":"Key Features","text":"<ul> <li>Compares means between treatment and control groups</li> <li>Calculates p-values to determine statistical significance</li> <li>Provides absolute difference between group means with confidence intervals</li> <li>Calculates relative difference (percentage change) with confidence intervals</li> <li>Supports customizable confidence levels</li> </ul>"},{"location":"api/analysis/#when-to-use-t-tests","title":"When to Use T-Tests","text":"<p>T-tests are appropriate when:</p> <ul> <li>You have a binary treatment variable (e.g., control vs. treatment)</li> <li>Your target variable is continuous or binary</li> <li>You want to determine if there's a statistically significant difference between groups</li> <li>You need to quantify the magnitude of the effect with confidence intervals</li> </ul>"},{"location":"api/analysis/#example-usage","title":"Example Usage","text":"<pre><code>from causalkit.data import generate_rct_data, CausalData\nfrom causalkit.inference import ttest\n\n# Generate sample RCT data\ndf = generate_rct_data(\n    n_users=10000,\n    split=0.5,\n    target_type=\"normal\",\n    target_params={\"mean\": {\"A\": 10.0, \"B\": 10.5}, \"std\": 2.0},\n    random_state=42\n)\n\n# Create causaldata object\nck = CausalData(\n    df=df,\n    target='target',\n    treatment='treatment'\n)\n\n# Perform t-test with 95% confidence level\nresults = ttest(ck, confidence_level=0.95)\n\n# Print results\nprint(f\"P-value: {results['p_value']:.4f}\")\nprint(f\"Absolute difference: {results['absolute_difference']:.4f}\")\nprint(f\"Absolute CI: {results['absolute_ci']}\")\nprint(f\"Relative difference: {results['relative_difference']:.2f}%\")\nprint(f\"Relative CI: {results['relative_ci']}\")\n</code></pre>"},{"location":"api/analysis/#interpreting-results","title":"Interpreting Results","text":"<ul> <li>p-value: Indicates the probability of observing the data if there is no true difference between groups. A small p-value (typically &lt; 0.05) suggests that the observed difference is statistically significant.</li> <li>absolute_difference: The raw difference between the treatment and control means.</li> <li>absolute_ci: Confidence interval for the absolute difference. If this interval does not include zero, the difference is statistically significant.</li> <li>relative_difference: The percentage change relative to the control group mean.</li> <li>relative_ci: Confidence interval for the relative difference.</li> </ul>"},{"location":"api/analysis/#api-reference","title":"API Reference","text":"<p>T-test inference for causaldata objects.</p>"},{"location":"api/analysis/#causalkit.inference.ttest.ttest","title":"<code>ttest(data, confidence_level=0.95)</code>","text":"<p>Perform a t-test on a causaldata object to compare the target variable between treatment groups.</p>"},{"location":"api/analysis/#causalkit.inference.ttest.ttest--parameters","title":"Parameters","text":"<p>data : CausalData     The causaldata object containing treatment and target variables. confidence_level : float, default 0.95     The confidence level for calculating confidence intervals (between 0 and 1).</p>"},{"location":"api/analysis/#causalkit.inference.ttest.ttest--returns","title":"Returns","text":"<p>Dict[str, Any]     A dictionary containing:     - p_value: The p-value from the t-test     - absolute_difference: The absolute difference between treatment and control means     - absolute_ci: Tuple of (lower, upper) bounds for the absolute difference confidence interval     - relative_difference: The relative difference (percentage change) between treatment and control means     - relative_ci: Tuple of (lower, upper) bounds for the relative difference confidence interval</p>"},{"location":"api/analysis/#causalkit.inference.ttest.ttest--raises","title":"Raises","text":"<p>ValueError     If the causaldata object doesn't have both treatment and target variables defined,     or if the treatment variable is not binary.</p>"},{"location":"api/analysis/#causalkit.inference.ttest.ttest--examples","title":"Examples","text":"<p>from causalkit.data import generate_rct_data from causalkit.data import CausalData from causalkit.inference import ttest</p> Source code in <code>causalkit/inference/ttest.py</code> <pre><code>def ttest(data: CausalData, confidence_level: float = 0.95) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform a t-test on a causaldata object to compare the target variable between treatment groups.\n\n    Parameters\n    ----------\n    data : CausalData\n        The causaldata object containing treatment and target variables.\n    confidence_level : float, default 0.95\n        The confidence level for calculating confidence intervals (between 0 and 1).\n\n    Returns\n    -------\n    Dict[str, Any]\n        A dictionary containing:\n        - p_value: The p-value from the t-test\n        - absolute_difference: The absolute difference between treatment and control means\n        - absolute_ci: Tuple of (lower, upper) bounds for the absolute difference confidence interval\n        - relative_difference: The relative difference (percentage change) between treatment and control means\n        - relative_ci: Tuple of (lower, upper) bounds for the relative difference confidence interval\n\n    Raises\n    ------\n    ValueError\n        If the causaldata object doesn't have both treatment and target variables defined,\n        or if the treatment variable is not binary.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from causalkit.data import generate_rct_data\n    &gt;&gt;&gt; from causalkit.data import CausalData\n    &gt;&gt;&gt; from causalkit.inference import ttest\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Generate data\n    &gt;&gt;&gt; df = generate_rct_data()\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Create causaldata object\n    &gt;&gt;&gt; ck = CausalData(\n    ...     df=df,\n    ...     target='target',\n    ...     treatment='treatment'\n    ... )\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Perform t-test\n    &gt;&gt;&gt; results = ttest(ck)\n    &gt;&gt;&gt; print(f\"P-value: {results['p_value']:.4f}\")\n    &gt;&gt;&gt; print(f\"Absolute difference: {results['absolute_difference']:.4f}\")\n    &gt;&gt;&gt; print(f\"Absolute CI: {results['absolute_ci']}\")\n    &gt;&gt;&gt; print(f\"Relative difference: {results['relative_difference']:.2f}%\")\n    &gt;&gt;&gt; print(f\"Relative CI: {results['relative_ci']}\")\n    \"\"\"\n    # Validate inputs\n    if data.treatment is None:\n        raise ValueError(\"causaldata object must have a treatment variable defined\")\n    if data.target is None:\n        raise ValueError(\"causaldata object must have a target variable defined\")\n\n    # Extract treatment and target data\n    treatment_var = data.treatment\n    target_var = data.target\n\n    # Check if treatment is binary\n    unique_treatments = treatment_var.unique()\n    if len(unique_treatments) != 2:\n        raise ValueError(\"Treatment variable must be binary (have exactly 2 unique values)\")\n\n    # Identify control and treatment groups\n    control_value = unique_treatments[0]\n    treatment_value = unique_treatments[1]\n\n    # Split data into control and treatment groups\n    control_data = target_var[treatment_var == 0]\n    treatment_data = target_var[treatment_var == 1]\n\n    # Perform t-test\n    t_stat, p_value = stats.ttest_ind(treatment_data, control_data, equal_var=True)\n\n    # Calculate means\n    control_mean = control_data.mean()\n    treatment_mean = treatment_data.mean()\n\n    # Calculate absolute difference\n    absolute_diff = treatment_mean - control_mean\n\n    # Calculate standard error of the difference\n    n1 = len(treatment_data)\n    n2 = len(control_data)\n    s1_squared = treatment_data.var(ddof=1)\n    s2_squared = control_data.var(ddof=1)\n\n    # Pooled variance\n    pooled_var = ((n1 - 1) * s1_squared + (n2 - 1) * s2_squared) / (n1 + n2 - 2)\n\n    # Standard error of the difference\n    se_diff = np.sqrt(pooled_var * (1/n1 + 1/n2))\n\n    # Calculate t-critical value for the given confidence level\n    alpha = 1 - confidence_level\n    df = n1 + n2 - 2  # Degrees of freedom\n    t_critical = stats.t.ppf(1 - alpha/2, df)\n\n    # Calculate confidence interval for absolute difference\n    margin_of_error = t_critical * se_diff\n    absolute_ci = (absolute_diff - margin_of_error, absolute_diff + margin_of_error)\n\n    # Calculate relative difference (percentage change)\n    if control_mean == 0:\n        # Handle division by zero\n        relative_diff = np.inf if absolute_diff &gt; 0 else -np.inf if absolute_diff &lt; 0 else 0\n        relative_ci = (np.nan, np.nan)  # Can't calculate CI when denominator is zero\n    else:\n        relative_diff = (absolute_diff / abs(control_mean)) * 100\n\n        # Calculate confidence interval for relative difference\n        relative_margin = (margin_of_error / abs(control_mean)) * 100\n        relative_ci = (relative_diff - relative_margin, relative_diff + relative_margin)\n\n    if not 0 &lt; confidence_level &lt; 1:\n        raise ValueError(\"confidence_level must be between 0 and 1 (exclusive)\")\n\n    # Return results as a dictionary\n    return {\n        \"p_value\": p_value,\n        \"absolute_difference\": absolute_diff,\n        \"absolute_ci\": absolute_ci,\n        \"relative_difference\": relative_diff,\n        \"relative_ci\": relative_ci\n    }\n</code></pre>"},{"location":"api/analysis/#causalkit.inference.ttest.ttest--generate-data","title":"Generate data","text":"<p>df = generate_rct_data()</p>"},{"location":"api/analysis/#causalkit.inference.ttest.ttest--create-causaldata-object","title":"Create causaldata object","text":"<p>ck = CausalData( ...     df=df, ...     target='target', ...     treatment='treatment' ... )</p>"},{"location":"api/analysis/#causalkit.inference.ttest.ttest--perform-t-test","title":"Perform t-test","text":"<p>results = ttest(ck) print(f\"P-value: {results['p_value']:.4f}\") print(f\"Absolute difference: {results['absolute_difference']:.4f}\") print(f\"Absolute CI: {results['absolute_ci']}\") print(f\"Relative difference: {results['relative_difference']:.2f}%\") print(f\"Relative CI: {results['relative_ci']}\")</p>"},{"location":"api/data/","title":"Data Module","text":"<p>The <code>causalkit.data</code> module provides functions for generating synthetic data for causal inference tasks.</p>"},{"location":"api/data/#overview","title":"Overview","text":"<p>This module includes functions for generating:</p> <ul> <li>A/B test data with customizable parameters</li> <li>Randomized Controlled Trial (RCT) data</li> <li>Observational data for more complex causal inference scenarios</li> </ul>"},{"location":"api/data/#api-reference","title":"API Reference","text":"<p>Data generation utilities for causal inference tasks.</p>"},{"location":"api/data/#causalkit.data.generators.generate_obs_data","title":"<code>generate_obs_data(n_users=20000, split=0.1, random_state=42)</code>","text":"<p>Create synthetic observational data where treatment assignment is influenced by covariates.</p>"},{"location":"api/data/#causalkit.data.generators.generate_obs_data--parameters","title":"Parameters","text":"<p>n_users     Total number of users in the dataset. split     Proportion of users in the treatment group. For example, 0.1 means 10% of users     will be in the treatment group and 90% in the control group. random_state     Seed for reproducibility.</p>"},{"location":"api/data/#causalkit.data.generators.generate_obs_data--returns","title":"Returns","text":"<p>pd.DataFrame     Columns: user_id, treatment, age, income, education, gender, region</p> Source code in <code>causalkit/data/generators.py</code> <pre><code>def generate_obs_data(\n    n_users: int = 20_000,\n    split: float = 0.1,\n    random_state: Optional[int] = 42,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Create synthetic observational data where treatment assignment is influenced by covariates.\n\n    Parameters\n    ----------\n    n_users\n        Total number of users in the dataset.\n    split\n        Proportion of users in the treatment group. For example, 0.1 means 10% of users\n        will be in the treatment group and 90% in the control group.\n    random_state\n        Seed for reproducibility.\n\n    Returns\n    -------\n    pd.DataFrame\n        Columns: user_id, treatment, age, income, education, gender, region\n    \"\"\"\n    # Set random seed for reproducibility\n    rng = np.random.default_rng(random_state)\n\n    # Generate user_ids\n    user_ids = [str(uuid.uuid4()) for _ in range(n_users)]\n\n    # Generate covariates\n    age = rng.normal(35, 10, n_users).round().clip(18, 80).astype(int)\n    income = rng.normal(50000, 15000, n_users).round().clip(10000, 150000).astype(int)\n    education = rng.choice(['high_school', 'bachelor', 'master', 'phd'], n_users, p=[0.3, 0.4, 0.2, 0.1])\n    gender = rng.choice(['male', 'female'], n_users)\n    region = rng.choice(['north', 'south', 'east', 'west', 'central'], n_users)\n\n    # Generate propensity scores (probability of treatment) based on covariates\n    # Higher income and education level increase probability of treatment\n    income_norm = (income - income.min()) / (income.max() - income.min())\n    education_score = np.where(education == 'high_school', 0.1,\n                      np.where(education == 'bachelor', 0.3,\n                      np.where(education == 'master', 0.5, 0.7)))\n\n    # Calculate base propensity\n    propensity = 0.2 * income_norm + 0.3 * education_score + 0.1 * (age / 80)\n\n    # Adjust to match desired split ratio\n    propensity = propensity * (split / propensity.mean())\n    propensity = np.clip(propensity, 0, 1)\n\n    # Assign treatment based on propensity\n    treatment = rng.binomial(1, propensity)\n\n    # Ensure exact split ratio\n    current_split = treatment.mean()\n    if current_split != split:\n        # Adjust by randomly flipping some assignments\n        if current_split &lt; split:\n            # Need to increase treatment\n            n_to_flip = int((split - current_split) * n_users)\n            control_indices = np.where(treatment == 0)[0]\n            flip_indices = rng.choice(control_indices, n_to_flip, replace=False)\n            treatment[flip_indices] = 1\n        else:\n            # Need to decrease treatment\n            n_to_flip = int((current_split - split) * n_users)\n            treatment_indices = np.where(treatment == 1)[0]\n            flip_indices = rng.choice(treatment_indices, n_to_flip, replace=False)\n            treatment[flip_indices] = 0\n\n    # Create DataFrame\n    df = pd.DataFrame({\n        'user_id': user_ids,\n        'treatment': treatment,\n        'age': age,\n        'income': income,\n        'education': education,\n        'gender': gender,\n        'region': region\n    })\n\n    return df\n</code></pre>"},{"location":"api/data/#causalkit.data.generators.generate_rct_data","title":"<code>generate_rct_data(n_users=20000, split=0.5, random_state=42, target_type='binary', target_params=None)</code>","text":"<p>Create synthetic RCT data with     \u2022 three possible target distributions (binary, continuous-normal,       continuous-non-normal),     \u2022 five covariates   \u2500 age, cnt_trans, platform_Android, platform_iOS,                           invited_friend       that are generated conditional on the target but remain independent       of the treatment group (groups are perfectly randomised).</p>"},{"location":"api/data/#causalkit.data.generators.generate_rct_data--parameters","title":"Parameters","text":"<p>n_users     Total number of users in the dataset. split     Proportion of users in the treatment group. For example, 0.5 means 50% of users     will be in the treatment group and 50% in the control group. random_state     Seed for reproducibility. target_type     Target distribution: \"binary\", \"normal\", or \"nonnormal\". target_params     Distribution parameters.  If None sensible defaults are used:         binary   : {\"p\": {\"A\": 0.10, \"B\": 0.12}}         normal   : {\"mean\": {\"A\": 0.00, \"B\": 0.20}, \"std\": 1.0}         nonnormal: {\"shape\": 2.0, \"scale\": {\"A\": 1.0, \"B\": 1.1}}</p>"},{"location":"api/data/#causalkit.data.generators.generate_rct_data--returns","title":"Returns","text":"<p>pd.DataFrame     Columns: user_id, treatment, target, age, cnt_trans,              platform_Android, platform_iOS, invited_friend.</p> Source code in <code>causalkit/data/generators.py</code> <pre><code>def generate_rct_data(\n    n_users: int = 20_000,\n    split: float = 0.5,\n    random_state: Optional[int] = 42,\n    target_type: str = \"binary\",                         # {\"binary\", \"normal\", \"nonnormal\"}\n    target_params: Optional[Dict] = None,                # distribution specifics (see docstring)\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Create synthetic RCT data with\n        \u2022 three possible target distributions (binary, continuous-normal,\n          continuous-non-normal),\n        \u2022 five covariates   \u2500 age, cnt_trans, platform_Android, platform_iOS,\n                              invited_friend\n          that are generated *conditional on the target* but remain independent\n          of the treatment group (groups are perfectly randomised).\n\n    Parameters\n    ----------\n    n_users\n        Total number of users in the dataset.\n    split\n        Proportion of users in the treatment group. For example, 0.5 means 50% of users\n        will be in the treatment group and 50% in the control group.\n    random_state\n        Seed for reproducibility.\n    target_type\n        Target distribution: \"binary\", \"normal\", or \"nonnormal\".\n    target_params\n        Distribution parameters.  If *None* sensible defaults are used:\n            binary   : {\"p\": {\"A\": 0.10, \"B\": 0.12}}\n            normal   : {\"mean\": {\"A\": 0.00, \"B\": 0.20}, \"std\": 1.0}\n            nonnormal: {\"shape\": 2.0, \"scale\": {\"A\": 1.0, \"B\": 1.1}}\n\n    Returns\n    -------\n    pd.DataFrame\n        Columns: user_id, treatment, target, age, cnt_trans,\n                 platform_Android, platform_iOS, invited_friend.\n    \"\"\"\n    # ------------------------------------------------------------------ #\n    # RNG &amp; default parameters\n    # ------------------------------------------------------------------ #\n    rng = np.random.default_rng(random_state)\n\n    # Calculate number of users in each group\n    n_treatment = int(n_users * split)\n    n_control = n_users - n_treatment\n\n    n_samples = {\"B\": n_treatment, \"A\": n_control}  # B for treatment, A for control\n\n    if target_params is None:\n        if target_type == \"binary\":\n            target_params = {\"p\": {\"A\": 0.10, \"B\": 0.12}}\n        elif target_type == \"normal\":\n            target_params = {\"mean\": {\"A\": 0.00, \"B\": 0.20}, \"std\": 1.0}\n        elif target_type == \"nonnormal\":\n            target_params = {\"shape\": 2.0, \"scale\": {\"A\": 1.0, \"B\": 1.1}}\n        else:\n            raise ValueError(\"target_type must be 'binary', 'normal', or 'nonnormal'.\")\n\n    # ------------------------------------------------------------------ #\n    # Data generation loop per group\n    # ------------------------------------------------------------------ #\n    frames = []\n\n    for grp, n in n_samples.items():\n        # -------- target ------------------------------------------------\n        if target_type == \"binary\":\n            target = rng.binomial(1, target_params[\"p\"][grp], n)\n        elif target_type == \"normal\":\n            mu, sigma = target_params[\"mean\"][grp], target_params[\"std\"]\n            target = rng.normal(mu, sigma, n)\n        else:  # non-normal (Gamma)\n            k, theta = target_params[\"shape\"], target_params[\"scale\"][grp]\n            target = rng.gamma(k, theta, n)\n\n        # -------- covariates (all depend on `target`, never on `grp`) ----\n        age = rng.normal(35 + 4 * target, 8, n).round().clip(18, 90).astype(int)\n\n        cnt_trans = rng.poisson(1.5 + 2 * target, n).astype(int)\n\n        # Android probability via simple logistic model\n        p_android = 1 / (1 + np.exp(-(-0.4 + 0.8 * target)))\n        platform_android = rng.binomial(1, p_android, n)\n        platform_ios = 1 - platform_android\n\n        # Invited a friend \u2192 more likely for larger target values\n        # Normalise target into [0,1] to keep probabilities valid\n        t_norm = (target - target.min()) / (target.max() - target.min() + 1e-8)\n        invited_friend = rng.binomial(1, 0.05 + 0.25 * t_norm, n)\n\n        # Generate UUID user_ids\n        user_ids = [str(uuid.uuid4()) for _ in range(n)]\n\n        # Convert group to treatment (1 for treatment, 0 for control)\n        treatment = 1 if grp == \"B\" else 0\n\n        # -------- assemble ---------------------------------------------\n        df_grp = pd.DataFrame(\n            {\n                \"user_id\": user_ids,\n                \"treatment\": [treatment] * n,\n                \"target\": target,\n                \"age\": age,\n                \"cnt_trans\": cnt_trans,\n                \"platform_Android\": platform_android,\n                \"platform_iOS\": platform_ios,\n                \"invited_friend\": invited_friend,\n            }\n        )\n        frames.append(df_grp)\n\n    return pd.concat(frames, ignore_index=True)\n</code></pre>"},{"location":"api/design/","title":"Design Module","text":"<p>The <code>causalkit.design</code> module provides utilities for designing experiments and splitting traffic.</p>"},{"location":"api/design/#overview","title":"Overview","text":"<p>This module includes functions for:</p> <ul> <li>Splitting traffic for experiments with customizable ratios</li> <li>Supporting stratified splitting to maintain distribution of key variables</li> </ul>"},{"location":"api/design/#api-reference","title":"API Reference","text":"<p>Utility functions for splitting traffic data from DataFrames.</p>"},{"location":"api/design/#causalkit.design.traffic_splitter.split_traffic","title":"<code>split_traffic(df, split_ratio=0.5, stratify_column=None, random_state=None)</code>","text":"<p>Split a DataFrame into multiple parts based on the specified ratio.</p>"},{"location":"api/design/#causalkit.design.traffic_splitter.split_traffic--parameters","title":"Parameters","text":"<p>df : pd.DataFrame     The input DataFrame containing traffic data. split_ratio : float or list of floats, default 0.5     If float, represents the proportion of the DataFrame to include in the first split.     If list, each value represents the proportion for each split. The values should sum to 1. stratify_column : str, optional     Column name to use for stratified splitting. If provided, the splits will have     the same proportion of values in this column. random_state : int, optional     Random seed for reproducibility.</p>"},{"location":"api/design/#causalkit.design.traffic_splitter.split_traffic--returns","title":"Returns","text":"<p>tuple of pd.DataFrame     A tuple containing the split DataFrames. If split_ratio is a float, returns a tuple of two DataFrames.     If split_ratio is a list, returns a tuple with length equal to len(split_ratio) + 1.</p>"},{"location":"api/design/#causalkit.design.traffic_splitter.split_traffic--examples","title":"Examples","text":"<p>import pandas as pd df = pd.DataFrame({'user_id': range(100), 'group': ['A', 'B'] * 50}) train_df, test_df = split_traffic(df, split_ratio=0.8, random_state=42) len(train_df), len(test_df) (80, 20)</p> <p>train_df, val_df, test_df = split_traffic(df, split_ratio=[0.7, 0.2], random_state=42) len(train_df), len(val_df), len(test_df) (70, 20, 10)</p> Source code in <code>causalkit/design/traffic_splitter.py</code> <pre><code>def split_traffic(\n    df: pd.DataFrame,\n    split_ratio: Union[float, List[float]] = 0.5,\n    stratify_column: Optional[str] = None,\n    random_state: Optional[int] = None\n) -&gt; Tuple[pd.DataFrame, ...]:\n    \"\"\"\n    Split a DataFrame into multiple parts based on the specified ratio.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The input DataFrame containing traffic data.\n    split_ratio : float or list of floats, default 0.5\n        If float, represents the proportion of the DataFrame to include in the first split.\n        If list, each value represents the proportion for each split. The values should sum to 1.\n    stratify_column : str, optional\n        Column name to use for stratified splitting. If provided, the splits will have\n        the same proportion of values in this column.\n    random_state : int, optional\n        Random seed for reproducibility.\n\n    Returns\n    -------\n    tuple of pd.DataFrame\n        A tuple containing the split DataFrames. If split_ratio is a float, returns a tuple of two DataFrames.\n        If split_ratio is a list, returns a tuple with length equal to len(split_ratio) + 1.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; df = pd.DataFrame({'user_id': range(100), 'group': ['A', 'B'] * 50})\n    &gt;&gt;&gt; train_df, test_df = split_traffic(df, split_ratio=0.8, random_state=42)\n    &gt;&gt;&gt; len(train_df), len(test_df)\n    (80, 20)\n\n    &gt;&gt;&gt; train_df, val_df, test_df = split_traffic(df, split_ratio=[0.7, 0.2], random_state=42)\n    &gt;&gt;&gt; len(train_df), len(val_df), len(test_df)\n    (70, 20, 10)\n    \"\"\"\n    np.random.seed(random_state)\n\n    if isinstance(split_ratio, float):\n        split_ratio = [split_ratio]\n\n    # Validate split_ratio\n    if sum(split_ratio) &gt;= 1:\n        raise ValueError(\"Sum of split ratios should be less than 1.\")\n\n    # Calculate the cumulative split points\n    cum_splits = np.cumsum(split_ratio)\n\n    # Create a list to store the split DataFrames\n    split_dfs = []\n\n    if stratify_column is not None and stratify_column in df.columns:\n        # Stratified split\n        unique_strata = df[stratify_column].unique()\n        strata_dfs = []\n\n        for stratum in unique_strata:\n            stratum_df = df[df[stratify_column] == stratum].copy()\n            stratum_indices = stratum_df.index.tolist()\n            np.random.shuffle(stratum_indices)\n\n            # Calculate split indices for this stratum\n            stratum_splits = [int(len(stratum_indices) * split) for split in cum_splits]\n\n            # Initialize list for this stratum's splits\n            stratum_split_dfs = []\n\n            # First split\n            stratum_split_dfs.append(stratum_df.loc[stratum_indices[:stratum_splits[0]]])\n\n            # Middle splits (if any)\n            for i in range(1, len(stratum_splits)):\n                stratum_split_dfs.append(\n                    stratum_df.loc[stratum_indices[stratum_splits[i-1]:stratum_splits[i]]]\n                )\n\n            # Last split\n            stratum_split_dfs.append(stratum_df.loc[stratum_indices[stratum_splits[-1]:]])\n\n            strata_dfs.append(stratum_split_dfs)\n\n        # Combine strata for each split\n        for i in range(len(cum_splits) + 1):\n            split_dfs.append(pd.concat([strata_df[i] for strata_df in strata_dfs], axis=0))\n    else:\n        # Random split\n        indices = df.index.tolist()\n        np.random.shuffle(indices)\n\n        # Calculate split indices\n        splits = [int(len(indices) * split) for split in cum_splits]\n\n        # First split\n        split_dfs.append(df.loc[indices[:splits[0]]])\n\n        # Middle splits (if any)\n        for i in range(1, len(splits)):\n            split_dfs.append(df.loc[indices[splits[i-1]:splits[i]]])\n\n        # Last split\n        split_dfs.append(df.loc[indices[splits[-1]:]])\n\n    return tuple(split_dfs)\n</code></pre>"},{"location":"examples/rct_analysis/","title":"CausalData","text":"<pre><code>from causalkit.data import generate_rct_data\nfrom causalkit.data import CausalData\nfrom causalkit.inference import ttest\n</code></pre> <pre><code>df = generate_rct_data()\n</code></pre> <pre><code>df.columns\n</code></pre> <pre>\n<code>Index(['user_id', 'treatment', 'target', 'age', 'cnt_trans',\n       'platform_Android', 'platform_iOS', 'invited_friend'],\n      dtype='object')</code>\n</pre> <pre><code>cdata = CausalData(\n    df=df,\n    target='target',\n    cofounders=['age', 'cnt_trans',\n       'platform_Android', 'platform_iOS', 'invited_friend'],\n    treatment='treatment'\n)\n</code></pre> <pre><code>cdata.metadata\n</code></pre> <pre>\n<code>{}</code>\n</pre> <pre><code>ttest(cdata)\n</code></pre> <pre>\n<code>{'p_value': np.float64(0.00017501995114700586),\n 'absolute_difference': np.float64(0.0165),\n 'absolute_ci': (np.float64(0.007883204030438051),\n  np.float64(0.02511679596956195)),\n 'relative_difference': np.float64(16.467065868263475),\n 'relative_ci': (np.float64(7.867469092253545),\n  np.float64(25.066662644273407))}</code>\n</pre> <pre><code>df.groupby('treatment')['target'].mean()\n</code></pre> <pre>\n<code>treatment\n0    0.1002\n1    0.1167\nName: target, dtype: float64</code>\n</pre> <pre><code>\"\"\"\nTest script to verify the ttest function in the inference module.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom causalkit.data import CausalData\nfrom causalkit.inference.ttest import ttest\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Create a test DataFrame with a known effect size\nn = 1000\ncontrol_mean = 10.0\ntreatment_effect = 2.0\ntreatment_mean = control_mean + treatment_effect\n\n# Create data with treatment effect\ndf = pd.DataFrame({\n    'user_id': range(1, n + 1),\n    'treatment': np.random.choice([0, 1], size=n),\n    'age': np.random.randint(18, 65, size=n),\n    'gender': np.random.choice(['M', 'F'], size=n),\n})\n\n# Generate target variable with treatment effect\ndf['target'] = np.where(\n    df['treatment'] == 1,\n    np.random.normal(treatment_mean, 2.0, size=n),  # Treatment group\n    np.random.normal(control_mean, 2.0, size=n)     # Control group\n)\n\n# Create a causaldata object\nck = CausalData(\n    df=df,\n    target='target',\n    cofounders=['age', 'gender'],\n    treatment='treatment'\n)\n\n# Test 1: Basic functionality\nprint(\"Test 1: Basic functionality\")\nresult = ttest(ck)\nprint(f\"p_value: {result['p_value']}\")\nprint(f\"absolute_difference: {result['absolute_difference']}\")\nprint(f\"absolute_ci: {result['absolute_ci']}\")\nprint(f\"relative_difference: {result['relative_difference']}\")\nprint(f\"relative_ci: {result['relative_ci']}\")\nprint()\n\n# Test 2: Check if absolute difference is close to the expected treatment effect\nprint(\"Test 2: Check if absolute difference is close to the expected treatment effect\")\nexpected_diff = treatment_effect\nactual_diff = result['absolute_difference']\ndiff_error = abs(actual_diff - expected_diff)\nprint(f\"Expected difference: {expected_diff}\")\nprint(f\"Actual difference: {actual_diff}\")\nprint(f\"Error: {diff_error}\")\nprint(f\"Test passed: {diff_error &amp;lt; 0.5}\")  # Allow for some random variation\nprint()\n\n# Test 3: Check if confidence intervals contain the true effect\nprint(\"Test 3: Check if confidence intervals contain the true effect\")\nlower_bound, upper_bound = result['absolute_ci']\ncontains_true_effect = lower_bound &amp;lt;= expected_diff &amp;lt;= upper_bound\nprint(f\"Confidence interval: ({lower_bound:.4f}, {upper_bound:.4f})\")\nprint(f\"True effect: {expected_diff}\")\nprint(f\"CI contains true effect: {contains_true_effect}\")\nprint()\n\n# Test 4: Check relative difference\nprint(\"Test 4: Check relative difference\")\nexpected_rel_diff = (treatment_effect / control_mean) * 100\nactual_rel_diff = result['relative_difference']\nrel_diff_error = abs(actual_rel_diff - expected_rel_diff)\nprint(f\"Expected relative difference: {expected_rel_diff:.2f}%\")\nprint(f\"Actual relative difference: {actual_rel_diff:.2f}%\")\nprint(f\"Error: {rel_diff_error:.2f}%\")\nprint(f\"Test passed: {rel_diff_error &amp;lt; 5}\")  # Allow for some random variation\nprint()\n\n# Test 5: Different confidence level\nprint(\"Test 5: Different confidence level\")\nresult_90 = ttest(ck, confidence_level=0.90)\nresult_99 = ttest(ck, confidence_level=0.99)\n\n# 90% CI should be narrower than 95% CI (default)\nci_width_90 = result_90['absolute_ci'][1] - result_90['absolute_ci'][0]\nci_width_95 = result['absolute_ci'][1] - result['absolute_ci'][0]\nci_width_99 = result_99['absolute_ci'][1] - result_99['absolute_ci'][0]\n\nprint(f\"90% CI width: {ci_width_90:.4f}\")\nprint(f\"95% CI width: {ci_width_95:.4f}\")\nprint(f\"99% CI width: {ci_width_99:.4f}\")\nprint(f\"Test passed: {ci_width_90 &amp;lt; ci_width_95 &amp;lt; ci_width_99}\")\nprint()\n\n# Test 6: Error handling - no treatment\nprint(\"Test 6: Error handling - no treatment\")\nck_no_treatment = CausalData(\n    df=df,\n    target='target',\n    cofounders=['age', 'gender']\n)\ntry:\n    result = ttest(ck_no_treatment)\n    print(\"Error: Test failed - should have raised ValueError\")\nexcept ValueError as e:\n    print(f\"Success: Correctly raised ValueError: {e}\")\nprint()\n\n# Test 7: Error handling - no target\nprint(\"Test 7: Error handling - no target\")\nck_no_target = CausalData(\n    df=df,\n    cofounders=['age', 'gender'],\n    treatment='treatment'\n)\ntry:\n    result = ttest(ck_no_target)\n    print(\"Error: Test failed - should have raised ValueError\")\nexcept ValueError as e:\n    print(f\"Success: Correctly raised ValueError: {e}\")\nprint()\n\n# Test 8: Error handling - non-binary treatment\nprint(\"Test 8: Error handling - non-binary treatment\")\ndf_multi = df.copy()\ndf_multi['treatment'] = np.random.choice([0, 1, 2], size=n)\nck_multi = CausalData(\n    df=df_multi,\n    target='target',\n    cofounders=['age', 'gender'],\n    treatment='treatment'\n)\ntry:\n    result = ttest(ck_multi)\n    print(\"Error: Test failed - should have raised ValueError\")\nexcept ValueError as e:\n    print(f\"Success: Correctly raised ValueError: {e}\")\nprint()\n\nprint(\"All tests completed.\")\n</code></pre> <pre>\n<code>Test 1: Basic functionality\np_value: 1.4940213443180423e-50\nabsolute_difference: 1.9617748200899392\nabsolute_ci: (np.float64(1.718663386392377), np.float64(2.2048862537875014))\nrelative_difference: 19.648731193051145\nrelative_ci: (np.float64(17.213777312635003), np.float64(22.083685073467286))\n\nTest 2: Check if absolute difference is close to the expected treatment effect\nExpected difference: 2.0\nActual difference: 1.9617748200899392\nError: 0.0382251799100608\nTest passed: True\n\nTest 3: Check if confidence intervals contain the true effect\nConfidence interval: (1.7187, 2.2049)\nTrue effect: 2.0\nCI contains true effect: True\n\nTest 4: Check relative difference\nExpected relative difference: 20.00%\nActual relative difference: 19.65%\nError: 0.35%\nTest passed: True\n\nTest 5: Different confidence level\n90% CI width: 0.4079\n95% CI width: 0.4862\n99% CI width: 0.6395\nTest passed: True\n\nTest 6: Error handling - no treatment\nSuccess: Correctly raised ValueError: causaldata object must have a treatment variable defined\n\nTest 7: Error handling - no target\nSuccess: Correctly raised ValueError: causaldata object must have a target variable defined\n\nTest 8: Error handling - non-binary treatment\nSuccess: Correctly raised ValueError: Treatment variable must be binary (have exactly 2 unique values)\n\nAll tests completed.\n</code>\n</pre> <pre><code>\n</code></pre>"},{"location":"user-guide/causaldata/","title":"Working with CausalData","text":"<p>The <code>CausalData</code> class is a core component of CausalKit that helps you organize and manage your data for causal inference analysis. This guide explains how to use the <code>CausalData</code> class effectively.</p>"},{"location":"user-guide/causaldata/#overview","title":"Overview","text":"<p>The <code>CausalData</code> class wraps a pandas DataFrame and stores metadata about columns for causal inference analysis. It categorizes your data columns into three main types:</p> <ul> <li>Target: The outcome variable(s) you're measuring</li> <li>Treatment: The intervention or treatment variable(s)</li> <li>Cofounders: The covariates or confounding variables</li> </ul> <p>This organization makes it easier to perform causal inference analyses and ensures data quality through built-in validation.</p>"},{"location":"user-guide/causaldata/#creating-a-causaldata-object","title":"Creating a CausalData Object","text":"<p>You can create a <code>CausalData</code> object by passing a pandas DataFrame along with column specifications:</p> <pre><code>from causalkit.data import CausalData\nimport pandas as pd\n\n# Create a sample DataFrame\nsample_df = pd.DataFrame({\n    'user_id': range(100),\n    'age': [20 + i % 40 for i in range(100)],\n    'treatment': [i % 2 for i in range(100)],\n    'conversion': [0.1 + 0.05 * (i % 2) + 0.001 * i for i in range(100)]\n})\n\n# Create a CausalData object\nsample_causal_data = CausalData(\n    df=sample_df,\n    target='conversion',\n    treatment='treatment',\n    cofounders=['age']\n)\n</code></pre>"},{"location":"user-guide/causaldata/#requirements-and-validation","title":"Requirements and Validation","text":"<p>The <code>CausalData</code> class performs several validations when you create an object:</p> <ol> <li>The DataFrame cannot contain NaN values</li> <li>All specified columns must exist in the DataFrame</li> <li>Target, treatment, and cofounder columns must contain only numeric values (int or float)</li> </ol> <p>If any of these validations fail, an error will be raised with a descriptive message.</p>"},{"location":"user-guide/causaldata/#accessing-data","title":"Accessing Data","text":"<p>Once you've created a <code>CausalData</code> object, you can access the data in several ways:</p>"},{"location":"user-guide/causaldata/#accessing-the-full-dataframe","title":"Accessing the Full DataFrame","text":"<pre><code>from causalkit.data import CausalData\nimport pandas as pd\n\n# Create a sample DataFrame and CausalData object\nsample_df = pd.DataFrame({\n    'user_id': range(100),\n    'age': [20 + i % 40 for i in range(100)],\n    'treatment': [i % 2 for i in range(100)],\n    'conversion': [0.1 + 0.05 * (i % 2) + 0.001 * i for i in range(100)]\n})\n\nsample_causal_data = CausalData(\n    df=sample_df,\n    target='conversion',\n    treatment='treatment',\n    cofounders=['age']\n)\n\n# Get the full DataFrame\nfull_df = sample_causal_data.df\n</code></pre>"},{"location":"user-guide/causaldata/#accessing-specific-column-types","title":"Accessing Specific Column Types","text":"<pre><code>from causalkit.data import CausalData\nimport pandas as pd\n\n# Create a sample DataFrame and CausalData object\nsample_df = pd.DataFrame({\n    'user_id': range(100),\n    'age': [20 + i % 40 for i in range(100)],\n    'treatment': [i % 2 for i in range(100)],\n    'conversion': [0.1 + 0.05 * (i % 2) + 0.001 * i for i in range(100)]\n})\n\nsample_causal_data = CausalData(\n    df=sample_df,\n    target='conversion',\n    treatment='treatment',\n    cofounders=['age']\n)\n\n# Get the target variable(s)\ntarget = sample_causal_data.target\n\n# Get the treatment variable(s)\ntreatment = sample_causal_data.treatment\n\n# Get the cofounders/covariates\ncofounders = sample_causal_data.cofounders\n</code></pre> <p>If you specified multiple columns for any category (e.g., multiple target columns), the corresponding property will return a DataFrame. If you specified a single column, it will return a Series.</p>"},{"location":"user-guide/causaldata/#selective-data-retrieval","title":"Selective Data Retrieval","text":"<p>The <code>get_df()</code> method allows you to retrieve specific columns or column categories:</p> <pre><code>from causalkit.data import CausalData\nimport pandas as pd\n\n# Create a sample DataFrame and CausalData object\nsample_df = pd.DataFrame({\n    'user_id': range(100),\n    'age': [20 + i % 40 for i in range(100)],\n    'treatment': [i % 2 for i in range(100)],\n    'conversion': [0.1 + 0.05 * (i % 2) + 0.001 * i for i in range(100)]\n})\n\nsample_causal_data = CausalData(\n    df=sample_df,\n    target='conversion',\n    treatment='treatment',\n    cofounders=['age']\n)\n\n# Get specific columns by name\nspecific_cols = sample_causal_data.get_df(columns=['user_id', 'age'])\n\n# Get target and treatment columns\ntarget_treatment = sample_causal_data.get_df(include_target=True, include_treatment=True)\n\n# Get all columns except cofounders\nno_cofounders = sample_causal_data.get_df(include_target=True, include_treatment=True, columns=['user_id'])\n</code></pre>"},{"location":"user-guide/causaldata/#working-with-generated-data","title":"Working with Generated Data","text":"<p><code>CausalData</code> works seamlessly with CausalKit's data generation functions:</p> <pre><code>from causalkit.data import generate_rct_data, CausalData\n\n# Generate RCT data\nrct_df = generate_rct_data()\n\n# Create a CausalData object\nrct_causal_data = CausalData(\n    df=rct_df,\n    target='target',\n    treatment='treatment',\n    cofounders=['age', 'invited_friend']\n)\n\n# Now you can use this for inference\nprint(rct_causal_data.target.mean())\nprint(rct_causal_data.treatment.value_counts())\n</code></pre>"},{"location":"user-guide/causaldata/#multiple-targets-and-treatments","title":"Multiple Targets and Treatments","text":"<p><code>CausalData</code> supports multiple target and treatment columns:</p> <pre><code>from causalkit.data import CausalData\nimport pandas as pd\n\n# Create a sample DataFrame with multiple targets and treatments\nmulti_df = pd.DataFrame({\n    'user_id': range(100),\n    'age': [20 + i % 40 for i in range(100)],\n    'country': ['US' if i % 3 == 0 else 'UK' if i % 3 == 1 else 'CA' for i in range(100)],\n    'previous_purchases': [i % 10 for i in range(100)],\n    'email_campaign': [i % 2 for i in range(100)],\n    'app_notification': [i % 3 == 0 for i in range(100)],\n    'conversion': [0.1 + 0.05 * (i % 2) + 0.001 * i for i in range(100)],\n    'revenue': [10 * (i % 5) + 0.5 * i for i in range(100)]\n})\n\n# Create a CausalData object with multiple targets and treatments\nmulti_causal_data = CausalData(\n    df=multi_df,\n    target=['conversion', 'revenue'],\n    treatment=['email_campaign', 'app_notification'],\n    cofounders=['age', 'previous_purchases']\n)\n\n# Access multiple targets (returns a DataFrame)\ntargets = multi_causal_data.target\n\n# Access multiple treatments (returns a DataFrame)\ntreatments = multi_causal_data.treatment\n</code></pre>"},{"location":"user-guide/causaldata/#best-practices","title":"Best Practices","text":"<p>Here are some best practices for working with <code>CausalData</code>:</p> <ol> <li> <p>Clean your data before creating a CausalData object: Handle missing values and ensure numeric columns are properly formatted.</p> </li> <li> <p>Be explicit about column roles: Clearly identify which columns are targets, treatments, and cofounders to make your analysis more interpretable.</p> </li> <li> <p>Use meaningful column names: This makes your code more readable and helps prevent errors.</p> </li> <li> <p>Validate your data: Even though <code>CausalData</code> performs basic validation, it's good practice to validate your data before analysis.</p> </li> </ol>"},{"location":"user-guide/causaldata/#next-steps","title":"Next Steps","text":"<p>Now that you understand how to use the <code>CausalData</code> class, you can:</p> <ul> <li>Explore the API Reference for detailed documentation</li> <li>Check out the Examples for more complex use cases</li> <li>Learn about analysis techniques in the Analysis API</li> </ul> <p>For any questions or issues, please visit the GitHub repository.</p>"},{"location":"user-guide/getting-started/","title":"Getting Started with CausalKit","text":"<p>This guide will help you get started with CausalKit by walking through some basic examples.</p>"},{"location":"user-guide/getting-started/#basic-workflow","title":"Basic Workflow","text":"<p>A typical workflow with CausalKit involves:</p> <ol> <li>Generating or loading data</li> <li>Designing and implementing an experiment</li> <li>Analyzing the results</li> </ol> <p>Let's walk through each step with examples.</p>"},{"location":"user-guide/getting-started/#data-generation","title":"Data Generation","text":"<p>CausalKit provides several functions for generating synthetic data for causal inference tasks.</p>"},{"location":"user-guide/getting-started/#generating-ab-test-data","title":"Generating A/B Test Data","text":"<pre><code>from causalkit.data import generate_ab_test_data\n\n# Generate A/B test data with default parameters\ndf = generate_ab_test_data()\n\n# Generate A/B test data with custom parameters\ndf_custom = generate_ab_test_data(\n    n_samples={\"A\": 5000, \"B\": 5000},\n    conversion_rates={\"A\": 0.10, \"B\": 0.12},\n    random_state=42\n)\n\nprint(df_custom.head())\n</code></pre>"},{"location":"user-guide/getting-started/#generating-randomized-controlled-trial-rct-data","title":"Generating Randomized Controlled Trial (RCT) Data","text":"<pre><code>from causalkit.data import generate_rct_data\n\n# Generate RCT data with default parameters\ndf = generate_rct_data()\n\n# Generate RCT data with custom parameters\ndf_custom = generate_rct_data(\n    n_users=10000,\n    split=0.5,\n    target_type=\"binary\",\n    random_state=42\n)\n\nprint(df_custom.head())\n</code></pre>"},{"location":"user-guide/getting-started/#experimental-design","title":"Experimental Design","text":""},{"location":"user-guide/getting-started/#splitting-traffic","title":"Splitting Traffic","text":"<p>CausalKit provides utilities for splitting traffic data for experiments.</p> <pre><code>import pandas as pd\nfrom causalkit.design.traffic_splitter import split_traffic\n\n# Create a sample DataFrame\ndf = pd.DataFrame({\n    'user_id': range(1000),\n    'feature_1': np.random.normal(0, 1, 1000),\n    'feature_2': np.random.choice(['A', 'B', 'C'], 1000)\n})\n\n# Split into training and test sets (70% / 30%)\ntrain_df, test_df = split_traffic(df, split_ratio=0.7, random_state=42)\n\n# Split into training, validation, and test sets (60% / 20% / 20%)\ntrain_df, val_df, test_df = split_traffic(df, split_ratio=[0.6, 0.2], random_state=42)\n\n# Stratified split based on a categorical feature\ntrain_df, test_df = split_traffic(df, split_ratio=0.7, stratify_column='feature_2', random_state=42)\n</code></pre>"},{"location":"user-guide/getting-started/#analysis","title":"Analysis","text":""},{"location":"user-guide/getting-started/#comparing-ab-test-results","title":"Comparing A/B Test Results","text":"<pre><code>import numpy as np\nfrom causalkit.inference import compare_ab\n\n# Generate some sample data\ncontrol = np.random.normal(10, 2, 1000)  # Control group data\ntreatment = np.random.normal(10.5, 2, 1000)  # Treatment group data\n\n# Compare the results\ncompare_ab(control, treatment)\n</code></pre>"},{"location":"user-guide/getting-started/#advanced-analysis-with-plr","title":"Advanced Analysis with PLR","text":"<pre><code>from causalkit.inference import compare_ab_with_plr\n\n# Compare using Partial Linear Regression\ncompare_ab_with_plr(control, treatment)\n</code></pre>"},{"location":"user-guide/getting-started/#next-steps","title":"Next Steps","text":"<p>Now that you're familiar with the basic functionality of CausalKit, you can:</p> <ul> <li>Explore the API Reference for detailed documentation of all functions</li> <li>Check out the Examples for more complex use cases</li> <li>Read about advanced topics in causal inference in the user guide</li> </ul> <p>For any questions or issues, please visit the GitHub repository.</p>"},{"location":"user-guide/installation/","title":"Installation","text":"<p>CausalKit can be installed using pip or from source.</p>"},{"location":"user-guide/installation/#prerequisites","title":"Prerequisites","text":"<p>CausalKit requires:</p> <ul> <li>Python 3.7 or later</li> <li>NumPy</li> <li>Pandas</li> <li>SciPy</li> <li>Statsmodels</li> <li>DoubleML (for advanced methods)</li> </ul>"},{"location":"user-guide/installation/#installing-with-pip","title":"Installing with pip","text":"<p>The simplest way to install CausalKit is using pip:</p> <pre><code>pip install causalkit\n</code></pre> <p>This will install CausalKit and all its dependencies.</p>"},{"location":"user-guide/installation/#installing-from-source","title":"Installing from source","text":"<p>To install CausalKit from source:</p> <ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/yourusername/causalkit.git\n</code></pre> <ol> <li>Navigate to the cloned directory:</li> </ol> <pre><code>cd causalkit\n</code></pre> <ol> <li>Install the package in development mode:</li> </ol> <pre><code>pip install -e .\n</code></pre>"},{"location":"user-guide/installation/#verifying-the-installation","title":"Verifying the installation","text":"<p>You can verify that CausalKit is installed correctly by importing it in Python:</p> <pre><code>import causalkit\nprint(causalkit.__version__)\n</code></pre>"},{"location":"user-guide/installation/#installing-optional-dependencies","title":"Installing optional dependencies","text":"<p>For development or running tests, you can install additional dependencies:</p> <pre><code>pip install causalkit[dev]\n</code></pre> <p>This will install additional packages like pytest, flake8, and sphinx for development and testing.</p>"}]}